@article{Burden1989,
abstract = {A method for producing molecular identification numbers for hydrogen-depleted organic structures from the eigenvalues of a connectivity matrix is presented. Over 20000 structures have been successfully tested, and the method can also be used to produce a unique numbering for the atoms in a structure and to identify which atoms belong to each of the substructures of a disconnected main structure.},
author = {Burden, Frank R},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burden - 1989 - Molecular Identification Number for Substructure Searches.pdf:pdf},
journal = {J. Chem. InJ Comput. Sci},
pages = {225--221},
title = {{Molecular Identification Number for Substructure Searches}},
url = {http://pubs.acs.org/doi/pdf/10.1021/ci00063a011},
volume = {29},
year = {1989}
}
@article{Cherkasov2014,
author = {Cherkasov, Artem and Muratov, Eugene N and Fourches, Denis and Varnek, Alexandre and Baskin, Igor I and Cronin, Mark and Dearden, John C and Gramatica, Paola and Martin, Yvonne Connolly and Todeschini, Roberto and Consonni, Viviana and Kuz, Viktor E and Cramer, Richard David and Benigni, Romualdo and Yang, Chihae and Rathman, James F and Terfloth, Lothar and Gasteiger, Johann and Richard, Ann M and Tropsha, Alexander},
doi = {org/10.1021/jm4004285},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cherkasov et al. - 2014 - Perspective QSAR Modeling Where have you been Where are you going to QSAR Modeling Where have you been Wh.pdf:pdf},
journal = {Journal of Medicinal Chemistry},
title = {{QSAR Modeling: Where have you been? Where are you going to?}},
year = {2014}
}
@book{James2013,
abstract = {File swarming (or file sharing) is one of the most important applications in P2P networks. In this paper, we propose a stochastic framework to analyze a file-swarming system under realistic setting: constraints in upload/download capacity, collaboration among peers and incentive for chunk exchange. We first extend the results in the coupon system [L. Massoulie, M. Vojnovic, Coupon replication systems, in: Proc. ACM SIGMETRICS, Banff, Alberta, Canada, 2005] by providing a tighter performance bound. Then we generalize the coupon system by considering peers with limited upload and download capacity. We illustrate the last-piece problem and show the effectiveness of using forward error-correction (FEC) code and/or multiple requests to improve the performance. Lastly, we propose a framework to analyze an incentive-based file-swarming system. The stochastic framework we propose can serve as a basis for other researchers to analyze and design more advanced features of file-swarming systems. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
address = {New York, NY},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
booktitle = {Performance Evaluation},
doi = {10.1007/978-1-4614-7138-7},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Vestige/Dropbox/st590/ISLR Sixth Printing.pdf:pdf},
isbn = {978-1-4614-7137-0},
issn = {01665316},
keywords = {BitTorrent,P2P file sharing,Performance modeling},
number = {9-12},
pages = {856--875},
pmid = {10911016},
publisher = {Springer New York},
series = {Springer Texts in Statistics},
title = {{An Introduction to Statistical Learning}},
url = {http://books.google.com/books?id=9tv0taI8l6YC http://link.springer.com/10.1007/978-1-4614-7138-7},
volume = {103},
year = {2013}
}
@article{Kim2009,
abstract = {a b s t r a c t We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the .632+ bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the .632+ bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the .632+ bootstrap estimator suffers from a bias problem for large samples as well as for small samples.},
author = {Kim, Ji-Hyun},
doi = {10.1016/j.csda.2009.04.009},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim - 2009 - Computational Statistics and Data Analysis Estimating classification error rate Repeated cross-validation, repeated hold-ou.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
month = {sep},
number = {11},
pages = {3735--3745},
title = {{Estimating classification error rate: Repeated cross-validation, repeated hold-out and bootstrap}},
url = {www.elsevier.com/locate/csda http://linkinghub.elsevier.com/retrieve/pii/S0167947309001601},
volume = {53},
year = {2009}
}
@book{Kuhn2013,
author = {Kuhn, Max and Johnson, Kjell},
doi = {10.1007/978-1-4614-6849-3},
file = {:C$\backslash$:/Users/Vestige/Downloads/bok{\%}3A978-1-4614-6849-3.pdf:pdf},
isbn = {1461468485},
pages = {620},
pmid = {17629633},
title = {{Applied Predictive Modeling}},
url = {http://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485/ref=pd{\_}bxgy{\_}b{\_}img{\_}z},
year = {2013}
}
@article{Molinaro2005,
author = {Molinaro, A. M. and Simon, R. and Pfeiffer, R. M.},
doi = {10.1093/bioinformatics/bti499},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Molinaro, Simon, Pfeiffer - 2005 - Prediction error estimation a comparison of resampling methods.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {aug},
number = {15},
pages = {3301--3307},
publisher = {Oxford University Press},
title = {{Prediction error estimation: a comparison of resampling methods}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bti499},
volume = {21},
year = {2005}
}
@article{Shen2011,
abstract = {Cross-validation (CV) is widely used for tuning a model with respect to user-selected parameters and for selecting a " best " model. For example, the method of k-nearest neighbors requires the user to choose k, the number of neighbors, and a neural network has several tuning parameters controlling the network complexity. Once such parameters are optimized for a particular data set, the next step is often to compare the various optimized models and choose the method with the best predictive performance. Both tuning and model se-lection boil down to comparing models, either across different values of the tuning parameters or across different classes of statistical models and/or sets of explanatory variables. For multiple large sets of data, like the PubChem drug discovery cheminformatics data which motivated this work, reliable CV comparisons are computationally demanding, or even infeasible. In this pa-per we develop an efficient sequential methodology for model comparison based on CV. It also takes into account the randomness in CV. The number of models is reduced via an adaptive, multiplicity-adjusted sequential algo-rithm, where poor performers are quickly eliminated. By exploiting matching of individual observations, it is sometimes even possible to establish the sta-tistically significant inferiority of some models with just one execution of CV.},
author = {Shen, Hui and Welch, William J and Hughes-Oliver, Jacqueline M},
doi = {10.1214/11-AOAS491},
file = {:C$\backslash$:/Users/Vestige/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Welch, Hughes-Oliver - 2011 - EFFICIENT, ADAPTIVE CROSS-VALIDATION FOR TUNING AND COMPARING MODELS, WITH APPLICATION TO DRUG DISCO.pdf:pdf},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {Assay data,PubChem,cheminformatics,drug discovery,k-nearest neighbors,multiplicity adjustment,neural network,randomized-block design,sequential analysis},
month = {dec},
number = {4},
pages = {2668--2687},
title = {{Efficient, adaptive cross-validation for tuning and comparing models, with application to drug discovery}},
url = {http://projecteuclid.org/euclid.aoas/1324399611{\%}5Cnpapers2://publication/uuid/6261B359-C0A2-4869-9546-989F31B76954 http://projecteuclid.org/euclid.aoas/1324399611},
volume = {5},
year = {2011}
}
