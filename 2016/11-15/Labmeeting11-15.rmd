---
title: "LabMeeting11-15"
author: "Jeremy Ash"
date: "November 15, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = "C:/Users/Vestige/Dropbox/ChemModLab/", fig.height=8, fig.width=8)
library(gplots)
library(caret)
library(doParallel)
library(doSNOW)

options(repos=c(CRAN="http://archive.linux.duke.edu/cran/"))
```

# Customizable Tuning Parameters

Now users can set tuning parameters manually.  I have implemented a `MakeModelDefaults` function that allows the user to create a list of the default parameters, which they can then modify.  I have also created a `PrintModelDefaults` function which will allow the user to see the model defaults in a prettier format. I have also implemented error handeling that throws error if parameters are set incorrectly (eg. multiple values for one parameter) and warnings if parameter values are not used.

Some issues I have encountered:

*  PCR
    +  How do I set the number of components to use for the homegrown PCR code?
    -   Do we still want to use the homegrown PCR code?
    -   Can tune `pls` and `pcr` functions in the `pls` package with caret
    -   Can also use the `RMSEP` function in `pls`
*  Nnet
    +  weight decay tuned
    +    regularizes the cost function  
        -  tunes the penalty for large weights and effectively limits the freedom of the model
    +    An easy way to do that is by introducing a zero mean Gaussian prior over the weights, which is equivalent to changing the cost function to: $\hat{E}(w)=E(w)+\frac{\lambda}{2}w^2$.  Larger weights are penalized more.
    +   No regression
    
*  Lars
    +   May be good to implement lasso with both lars and glmnet.  According to developer of scikit (and Dr. Bondell):
    
   LARS is faster for small problems, very sparse problems, or very 'wide' problems (much much more features than samples). Its computational cost is limited by the number of features selected, if you don't compute the full regularization path. On the other hand, for big problems, glmnet (coordinate descent optimization) is faster.
    
*  KNN
    +  No regression
    +    there is for discontinued KNNflex
*  rpart
    +    tune cp (complexity parameter):
    
    With anova splitting, this means that the overall R-squared must increase by cp at each step. The main role of this parameter is to save computing time by pruning off splits that are obviously not worthwhile. Essentially,the user informs the program that any split which does not improve the fit by cp will likely be pruned off by cross-validation, and that hence the program need not pursue it.
    
    +    can tune the size of the tree this way

*   tree
    +  need to implement cost complexity pruning
*   svm
    +  cannot tune the radial basis kernel with caret, only the linear kernel (probably because it is so slow to fit radial basis kernel svm)
    +  can tune with the `tune.svm` function in `e1071`
    +  caret does support tuning `kvm` a redial basis kernel svm in `kernlab`


I show how the user can first tune their parameters using caret and then set those model parameters in ChemModLab.  I also demonstrate how parallel processing is used in caret.

```{r fit model1, echo=T, cache=TRUE, results="hide"}

source("background_newparms.R")

yfilein <- read.csv("AID_364.csv")
xfilein1 <- read.csv("BurdenNumbers.csv")
data <- cbind(yfilein, xfilein1[,-1])
head(data[, 1:6])

bb <- ModelTrain(data, idcol=1, 
                 models = c("NNet","PCR","ENet","PLS","Ridge", "SVM",
                            "LARs","PLSLDA","RPart","Tree","KNN","Forest"),
                 nsplits = 3, nfolds=10)
```

```{r tune parameters, echo=T, cache=TRUE}

CombineSplits(bb, metric = "auc")


print(MakeModelDefaults)

user.params <- MakeModelDefaults(n = nrow(data[, -1]), p = ncol(data[, -1]), classify = T, nfolds = 10)

PrintModelDefaults(n = nrow(data[, -1]), p = ncol(data[, -1]), classify = T, nfolds = 10)

# tuning model parameters in caret

cl <- makeCluster(4)
registerDoParallel(cl)

data_caret <- data[, -1]

# need to make outcome a 2 class variable

data_caret$Outcome <- as.factor(ifelse(data_caret$Outcome == 1, "Active", "Inactive"))

fitControl <- trainControl(method = "CV", 10, classProbs = TRUE,
  summaryFunction = twoClassSummary)

set.seed(823)

rfFit <- train(Outcome ~ ., data = data_caret, method = "rf", 
  trControl = fitControl, verbose = FALSE, tuneLength = 10, metric = "ROC")

rfFit

user.params$Forest <- data.frame(mtry= 6)

set.seed(823)

rfFit <- train(Outcome ~ ., data = data_caret, method = "nnet", 
  trControl = fitControl, verbose = FALSE, tuneLength = 5, metric = "ROC")

rfFit

user.params$NNet <- data.frame(size = 5, decay = .1)

user.params$SVM <- data.frame(gamma = 2^-5, cost = 10^-2)

stopImplicitCluster()
```

```{r fit model2, echo=T, cache=TRUE, results="hide"}

# Do not need to make a list with all the parameters specified, can omit some
# and then the defaults will be used for those parameters:

# user.params <- list(NNet = data.frame(size = 3, decay = 0)

bb <- ModelTrain(data, idcol=1, 
                 models = c("NNet","PCR","ENet","PLS","Ridge",
                            
              "SVM","LARs","PLSLDA","RPart","Tree","KNN","Forest"),
                 nsplits = 3, nfolds=10, user.params = user.params)
```

```{r fit model2_cont, echo=T, cache=TRUE}
CombineSplits(bb, metric = "auc")
```
\pagebreak


# Tidying Up R Code

![Before tidying](C:/Users/Vestige/Dropbox/ChemModLab/example_run/untidy.jpeg)

![After tidying](C:/Users/Vestige/Dropbox/ChemModLab/example_run/tidy.jpeg)


# Parallel Processing

Taking the same approach as caret, I have taken initial steps in parallel processing. There are still a few challenges that need to be dealt with:

*  The output to the console is suppressed because now processes are being run  simultaneously.
    +  working on this
*  The foreach command returns a list that needs to be reformatted afterwards.  There is probably a more elegant way to have foreach return the right list format.

Looping over descriptor sets can be done in exactly the same way.  Will do this soon.

Here is a sample of the foreach command:

```{r echo=T, eval=F}

  Funcs <- as.vector(lsf.str())
  big.ls <- foreach (seed.idx = 1:nsplits, .packages = (.packages()),
           .export = Funcs) %dopar% {
    
    source("C:/Users/Vestige/Dropbox/ChemModLab/background_newparms.R")         
              
      
```

```{r do parallel, echo=T, cache=TRUE}
source("background_newparms.R")

system.time(
bb_1proc <- ModelTrain(data, idcol=1,
  models = c("NNet","PCR","ENet","PLS","Ridge",
                            
              "SVM","LARs","PLSLDA","RPart","Tree","KNN","Forest"), 
  nfolds=10, nsplits = 3, user.params = user.params)
)

source("background_parallel.R")

cl <- makeCluster(3, outfile="")
registerDoSNOW(cl)

system.time(
  bb_3proc <- ModelTrain(data, idcol=1,
                   models = c("NNet","PCR","ENet","PLS","Ridge",
                            
              "SVM","LARs","PLSLDA","RPart","Tree","KNN","Forest"),
                   nfolds=10, nsplits = 3, user.params = user.params)
)

# Are all the predictions equal?
for(i in 1:3){
  print(all.equal(bb_1proc$allpreds[[i]][[1]], bb_3proc$allpreds[[i]][[1]]))
}

# Are all the predicted probabilities equal?
for(i in 1:3){
  print(all.equal(bb_1proc$allprobs[[i]][[1]], bb_3proc$allprobs[[i]][[1]]))
}

stopImplicitCluster()
```

![Using 3 processors](C:/Users/Vestige/Dropbox/ChemModLab/example_run/parallel.jpeg)